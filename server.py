
import cv2
import numpy as np
from fastapi import FastAPI, UploadFile, File, Query
from fastapi.responses import StreamingResponse, HTMLResponse, FileResponse
import uvicorn
import os
import time
import logging
import subprocess

# ------------------------------------------------------------------
# åˆå¿ƒè€…ã¸ã®ãƒ¡ãƒ¢ï¼šã“ã®ã‚¢ãƒ—ãƒªã®ã€Œç²¾ç¥æ§‹é€ ã€
# ------------------------------------------------------------------
# 1. ã€å¿˜å´ã€‘
#    å‹•ç”»ã‚’èª­ã¿è¾¼ã‚€ãŒã€ä¸­èº«ã¯ä¸€åˆ‡è¦‹ãªã„ã€‚
#    ã€ŒèƒŒæ™¯ã€ã‚’å­¦ç¿’ã—ã€å‹•ã‹ãªã„ã‚‚ã®ã¯ã™ã¹ã¦ã€Œå›ºå®šã•ã‚ŒãŸç ‚æ¼ ï¼ˆé™æ­¢ãƒã‚¤ã‚ºï¼‰ã€ã¨ã—ã¦åŸ‹æ²¡ã•ã›ã‚‹ã€‚
# 2. ã€å’†å“®ã€‘
#    ã€Œå‹•ã„ãŸç¬é–“ã€ã ã‘ã€ãã®å½¢ã«åˆã‚ã›ã¦ã€Œæ¿€ã—ãå‹•ãç ‚åµï¼ˆå‹•çš„ãƒã‚¤ã‚ºï¼‰ã€ã‚’æµã—è¾¼ã‚€ã€‚
#    å…ƒã®è‰²ã¯æ¨ã¦å»ã‚‰ã‚Œã€æ¿€ã—ã•ã ã‘ãŒè¨˜éŒ²ã•ã‚Œã‚‹ã€‚
# 3. ã€åŠ é€Ÿã¨æ¸›é€Ÿã€‘
#    ã‚ãªãŸãŒè¨­å®šã§å¼„ã‚‹å€ç‡ã¯ã€æ™‚é–“ã®æµã‚Œï¼ˆå†ç”Ÿé€Ÿåº¦ï¼‰ã‚„ç©ºé–“ã®è§£åƒåº¦ã‚’æ­ªã‚ã‚‹é­”æ³•ã€‚
# 4. ã€ã—ã°ãå€’ã•ã‚Œã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã€‘
#    å·¨å¤§ãªãƒ¡ãƒ¢ãƒªã¯ã€ç ‚ç²’ãŸã¡ã®æºã‚Šã‹ã”ã§ã™ã€‚GPUã¯ã€ãã®è¨ˆç®—ã®åµã‚’è€ãˆå¿ã³ã¾ã™ã€‚
# ------------------------------------------------------------------

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.FileHandler("server.log", encoding='utf-8'), logging.StreamHandler()]
)
logger = logging.getLogger("NOICE")

app = FastAPI()
UPLOAD_DIR, OUTPUT_DIR = "uploads", "processed_videos"
for d in [UPLOAD_DIR, OUTPUT_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# --------------------------------------------------
# è´…æ²¢ãªãƒ†ã‚¯ã‚¹ãƒãƒ£ç”Ÿæˆ (åºƒå¤§ãªãƒ¡ãƒ¢ãƒªã‚’ã€Œã—ã°ãå€’ã™ã€ãŸã‚ã®è¶…å·¨å¤§ãƒ—ãƒ¼ãƒ«)
# --------------------------------------------------
def create_high_density_noise_pool(w, h, size=500, is_color=True):
    """
    ãƒ¡ãƒ¢ãƒªã‚’ã—ã°ãå€’ã—ã¦å¤§é‡ã®ãƒã‚¤ã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    åˆå¿ƒè€…ã®ã‚ãªãŸï¼šã‚µã‚¤ã‚ºã‚’500ã«å¢—ã‚„ã—ã¾ã—ãŸã€‚ã‚ãªãŸã®ãƒ¡ãƒ¢ãƒªãŒæ­“å–œã®æ‚²é³´ã‚’ä¸Šã’ã‚‹ã“ã¨ã§ã—ã‚‡ã†ã€‚
    """
    logger.info(f"ğŸŒ€ RAMæ¥µé™ã—ã°ããƒ¢ãƒ¼ãƒ‰: {size}å€‹ã®å·¨å¤§ãƒã‚¤ã‚ºãƒ†ã‚¯ã‚¹ãƒãƒ£ã‚’ç”Ÿæˆä¸­...")
    pool = []
    for i in range(size):
        if is_color:
            # ã‚«ãƒ©ãƒ¼ãƒã‚¤ã‚ºï¼šã‚ˆã‚Šè¤‡é›‘ãªã€æ²¹è†œã®ã‚ˆã†ãªã†ã­ã‚Šã‚’æŒãŸã›ã¾ã™
            noise = np.random.randint(0, 256, (h, w, 3), dtype=np.uint8)
            # ã‚ãšã‹ãªãƒ–ãƒ©ãƒ¼ã‚’ã‹ã‘ã¦ã€å˜ç´”ãªç‚¹ã§ã¯ãªãã€Œè³ªæ„Ÿã€ã‚’æŒãŸã›ã€GPUã¸ã®è² è·ã‚‚é«˜ã‚ã¾ã™
            noise = cv2.GaussianBlur(noise, (3, 3), 0)
        else:
            noise_gray = np.random.randint(0, 256, (h, w), dtype=np.uint8)
            noise = cv2.cvtColor(noise_gray, cv2.COLOR_GRAY2BGR)
        pool.append(noise)
        if i % 100 == 0: logger.info(f"ğŸ“Š Pool generation: {i}/{size}")
    return pool

# --------------------------------------------------
# æ„æ€æŠ½å‡ºã‚¨ãƒ³ã‚¸ãƒ³ (Mog2 + Multi-Gaussian Blur)
# --------------------------------------------------
def process_void_stream(temp_path: str, output_path: str, scale: float, is_color: bool, speed: float):
    cap = cv2.VideoCapture(temp_path)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    w = int(int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) * scale)
    h = int(int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * scale)
    
    # é™æ­¢ã—ãŸè™šç„¡ï¼ˆèƒŒæ™¯ï¼‰ã®å­¦ç¿’
    backSub = cv2.createBackgroundSubtractorMOG2(history=300, varThreshold=60, detectShadows=False)
    
    # ãƒ¡ãƒ¢ãƒªã‚’ä½¿ã„åˆ‡ã‚‹è¦šæ‚Ÿã§500æšå±•é–‹
    # 1080pã ã¨ã“ã‚Œã ã‘ã§æ•°GBã€œæ•°åGBç¨‹åº¦ã‚’å æœ‰ã—ã€ãã®ä»–ã®å‡¦ç†ã¨åˆã‚ã›ã¦ã€Œã—ã°ãã€ã‚’åŠ é€Ÿã•ã›ã¾ã™
    pool = create_high_density_noise_pool(w, h, size=500, is_color=is_color)
    static_noise = pool[0].copy() # 1æšç›®ã¯å›ºå®šèƒŒæ™¯ç”¨
    
    frame_delay = 1.0 / (fps * speed)
    p_idx = 0
    
    while True:
        start_time = time.time()
        ret, frame = cap.read()
        if not ret: break
        
        frame = cv2.resize(frame, (w, h))
        
        # å­˜åœ¨ã‚’æ¶ˆã—å»ã‚‹ãŸã‚ã®å¤šé‡ãƒ–ãƒ©ãƒ¼
        # GPUãªã‚‰ã“ã®ç¨‹åº¦ã®è¨ˆç®—ã¯å¤§ã—ãŸã“ã¨ã‚ã‚Šã¾ã›ã‚“
        frame_blurred = cv2.GaussianBlur(frame, (15, 15), 0)
        
        # å‹•ãï¼ˆæ„æ€ï¼‰ã®æŠ½å‡º
        mask = backSub.apply(frame_blurred)
        
        # ãƒã‚¹ã‚¯ã®æ´—ç·´ï¼šå°ã•ãªãƒã‚¤ã‚ºã‚’æ¶ˆã—ã€å¤§ããªã€Œæ„æ€ã®ã†ã­ã‚Šã€ã ã‘ã‚’æ®‹ã™
        mask = cv2.medianBlur(mask, 5)
        mask = cv2.dilate(mask, None, iterations=2)
        
        # è™šç„¡ã®æ§‹ç¯‰
        res = static_noise.copy()
        # æ„æ€ãŒç™ºç«ã—ãŸéƒ¨åˆ†ã ã‘ã€ã‚ˆã‚Šãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è±Šã‹ãªç ‚åµï¼ˆ500ç¨®ï¼‰ã‚’æµã—è¾¼ã‚€
        res[mask > 0] = pool[p_idx % 500][mask > 0]
        
        _, buffer = cv2.imencode('.jpg', res)
        yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
        p_idx += 1
        
        # é€Ÿåº¦åˆ¶å¾¡ï¼ˆPCã‚’ã„ãŸã‚ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã®ã¿æ©Ÿèƒ½ã—ã¾ã™ï¼‰
        process_time = time.time() - start_time
        wait_time = frame_delay - process_time
        if wait_time > 0:
            time.sleep(wait_time)
            
    cap.release()
    if os.path.exists(temp_path): os.remove(temp_path)

@app.get("/")
def main():
    with open("index.html", "r", encoding="utf-8") as f: return HTMLResponse(content=f.read())

@app.get("/style.css")
async def get_css(): return FileResponse("style.css")

@app.get("/main.js")
async def get_js(): return FileResponse("main.js")

@app.get("/logs")
async def get_logs():
    if not os.path.exists("server.log"): return {"logs": "System Initialized."}
    with open("server.log", "r", encoding="utf-8") as f: return {"logs": "".join(f.readlines()[-10:])}

@app.post("/upload")
async def upload_video(file: UploadFile = File(...)):
    ts = int(time.time())
    path = os.path.join(UPLOAD_DIR, f"void_{ts}_{file.filename.replace(' ', '_')}")
    with open(path, "wb") as b: b.write(await file.read())
    return {"temp_name": os.path.basename(path), "output_name": f"noice_void_{ts}.mp4"}

@app.get("/stream/{temp_name}/{output_name}")
async def stream_video(temp_name: str, output_name: str, scale: float = 0.5, is_color: bool = True, speed: float = 1.0):
    return StreamingResponse(process_void_stream(os.path.join(UPLOAD_DIR, temp_name), os.path.join(OUTPUT_DIR, output_name), scale, is_color, speed),
                             media_type="multipart/x-mixed-replace; boundary=frame")

import shutil
from moviepy.editor import VideoFileClip, AudioFileClip, AudioArrayClip, CompositeAudioClip
import numpy as np

# --------------------------------------------------
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å‡¦ç†
# --------------------------------------------------

def generate_noise_audio_clip(duration, noise_type='white'):
    """
    MoviePy/Numpyã‚’ä½¿ã£ã¦ãƒã‚¤ã‚ºéŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """
    rate = 44100
    n_samples = int(duration * rate)
    
    if noise_type == 'white':
        # ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚º
        noise = np.random.uniform(-0.1, 0.1, n_samples)
    elif noise_type == 'brown':
        # ãƒ–ãƒ©ã‚¦ãƒ³ãƒã‚¤ã‚º: ç´¯ç©å’Œ
        white = np.random.uniform(-0.1, 0.1, n_samples)
        noise = np.cumsum(white)
        max_val = np.max(np.abs(noise))
        if max_val > 0:
            noise = noise / max_val * 0.1
    else:
        return None

    # ã‚¹ãƒ†ãƒ¬ã‚ªåŒ– (2ãƒãƒ£ãƒ³ãƒãƒ«)
    noise = np.vstack((noise, noise)).T
    return AudioArrayClip(noise, fps=rate)

def save_processed_video(temp_path: str, output_path: str, scale: float, is_color: bool, audio_mode: str):
    cap = cv2.VideoCapture(temp_path)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    w = int(int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) * scale)
    h = int(int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) * scale)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # æ˜ åƒã®ä¸€æ™‚ä¿å­˜å…ˆ
    temp_silent_output = output_path + ".silent.mp4"
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(temp_silent_output, fourcc, fps, (w, h))
    
    backSub = cv2.createBackgroundSubtractorMOG2(history=300, varThreshold=60, detectShadows=False)
    # ä¿å­˜æ™‚ã‚‚ã‚‚ã¡ã‚ã‚“ã€ãƒ¡ãƒ¢ãƒªã«æ•¬æ„ã‚’è¡¨ã—ã¦å·¨å¤§ãƒ—ãƒ¼ãƒ«ã‚’ä½¿ç”¨
    pool = create_high_density_noise_pool(w, h, size=500, is_color=is_color)
    static_noise = pool[0].copy()
    
    p_idx = 0
    
    logger.info(f"ğŸ’¾ Rendering started: {output_path} (Audio: {audio_mode})")
    
    while True:
        ret, frame = cap.read()
        if not ret: break
        
        frame = cv2.resize(frame, (w, h))
        frame_blurred = cv2.GaussianBlur(frame, (15, 15), 0)
        mask = backSub.apply(frame_blurred)
        mask = cv2.medianBlur(mask, 5)
        mask = cv2.dilate(mask, None, iterations=2)
        
        res = static_noise.copy()
        res[mask > 0] = pool[p_idx % 500][mask > 0]
        
        out.write(res)
        p_idx += 1
        if p_idx % 50 == 0: logger.info(f" rendering... {p_idx}/{total_frames}")

    cap.release()
    out.release()
    
    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªåˆæˆãƒ•ã‚§ãƒ¼ã‚º (MoviePy)
    logger.info("ğŸ”Š Audio mixing phase (MoviePy)...")
    try:
        final_clip = VideoFileClip(temp_silent_output)
        
        if audio_mode == 'original':
            # å…ƒå‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º
            original_clip = VideoFileClip(temp_path)
            if original_clip.audio:
                final_clip = final_clip.set_audio(original_clip.audio)
            original_clip.close()
            
        elif audio_mode in ['white', 'brown']:
            # ãƒã‚¤ã‚ºç”Ÿæˆ
            noise_clip = generate_noise_audio_clip(final_clip.duration, audio_mode)
            if noise_clip:
                final_clip = final_clip.set_audio(noise_clip)
        
        # éŸ³å£°ä»˜ãã§æ›¸ãå‡ºã—
        final_clip.write_videofile(output_path, codec="libx264", audio_codec="aac", logger=None)
        final_clip.close()
            
    except Exception as e:
        logger.error(f"MoviePy Audio mixing failed: {e}")
        # å¤±æ•—æ™‚ã¯ã‚µã‚¤ãƒ¬ãƒ³ãƒˆç‰ˆã‚’ãƒªãƒãƒ¼ãƒ ã—ã¦çµ‚äº†
        if os.path.exists(temp_silent_output) and not os.path.exists(output_path):
            shutil.move(temp_silent_output, output_path)
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    if os.path.exists(temp_silent_output): os.remove(temp_silent_output)
    
    logger.info("âœ¨ Rendering complete with audio.")

@app.get("/process_download/{temp_name}/{output_name}")
async def process_download(temp_name: str, output_name: str, scale: float = 1.0, is_color: bool = True, audio_mode: str = 'mute'):
    try:
        save_processed_video(
            os.path.join(UPLOAD_DIR, temp_name), 
            os.path.join(OUTPUT_DIR, output_name), 
            scale, is_color, audio_mode
        )
        return {"status": "completed", "url": f"/download/{output_name}"}
    except Exception as e:
        logger.error(f"Rendering failed: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/download/{filename}")
async def download_file(filename: str):
    path = os.path.join(OUTPUT_DIR, filename)
    if os.path.exists(path):
        return FileResponse(path, media_type='video/mp4', filename=filename)
    return {"error": "File not found. è™šç„¡ã®ä¸­ã«æ¶ˆãˆãŸã‚ˆã†ã§ã™ã€‚"}

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)
